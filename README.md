# innvestigate_torch

Uma reimplementa√ß√£o da biblioteca iNNvestigate usando PyTorch. Suporta diversos m√©todos de explicabilidade como:

- Gradient (Saliency)
- Integrated Gradients
- SmoothGrad
- LRP (Z-Rule, Epsilon, AlphaBeta)
- NoiseTunnel
- GradCAM

## Instala√ß√£o

```bash
pip install .
```

## Exemplo de uso

```python
from analyzers.gradient import GradientAnalyzer
analyzer = GradientAnalyzer(model)
attribution = analyzer.analyze(input_tensor)
```


O arquivo example.py pode ser usado depois que a biblioteca for instalada


# innvestigate_torch

**innvestigate_torch** √© uma reimplementa√ß√£o da biblioteca [iNNvestigate](https://github.com/albermax/innvestigate) voltada para interpretabilidade de redes neurais, mas agora compat√≠vel com PyTorch. A biblioteca oferece m√∫ltiplos m√©todos de explica√ß√£o que ajudam a entender o comportamento interno de modelos de deep learning.

## M√©todos de Explicabilidade Suportados

### üîπ Gradient (Saliency)
Baseado nos gradientes da sa√≠da em rela√ß√£o √† entrada. Este m√©todo destaca quais pixels mais influenciam a previs√£o final. √â simples e r√°pido, mas pode ser sens√≠vel a ru√≠dos.

### üîπ Integrated Gradients *(removido do example.py por instabilidade em backpropagation de vari√°veis n√£o-folhas)*
Esse m√©todo estima a contribui√ß√£o dos pixels interpolando entre uma baseline (entrada nula) e a entrada real. Fornece atribui√ß√µes mais est√°veis do que o gradiente puro.

### üîπ SmoothGrad
Combina m√∫ltiplas execu√ß√µes do m√©todo de gradiente com pequenas perturba√ß√µes (ru√≠do gaussiano) na entrada. O objetivo √© reduzir ru√≠dos e destacar regi√µes mais relevantes da imagem.

### üîπ LRP (Layer-wise Relevance Propagation)
Explica a decis√£o do modelo redistribuindo o valor da sa√≠da (relev√¢ncia) para os neur√¥nios da entrada, camada por camada. Variantes implementadas:
- **Z-Rule**: redistribui relev√¢ncia com base em ativa√ß√µes positivas e pesos.
- **Epsilon Rule**: adiciona um pequeno termo para evitar divis√µes por zero e ru√≠dos.
- **AlphaBeta Rule**: balanceia contribui√ß√µes positivas (Œ±) e negativas (Œ≤).

### üîπ NoiseTunnel
Uma extens√£o do m√©todo base (ex: Gradient ou IG) que adiciona ru√≠do na entrada v√°rias vezes e agrega os resultados para suavizar e destacar padr√µes consistentes. Suporta:
- `smoothgrad`
- `smoothgrad_sq`

### üîπ GradCAM
Funciona com modelos CNN e utiliza os gradientes das √∫ltimas camadas convolucionais para gerar mapas de ativa√ß√£o, destacando regi√µes mais importantes da imagem para a predi√ß√£o.

---

## Instala√ß√£o

```bash
pip install .


```


Exemplo 1 <br>
![Texto Alternativo](Figura_1.png)
<br>
Exemplo 2<br>
![Texto Alternativo](Figura_2.png)
<br>
Exemplo 3<br>
![Texto Alternativo](Figura_3.png)
<br>
Exemplo 4<br>
![Texto Alternativo](Figura_4.png)
<br>

Exemplo 5<br>
![Texto Alternativo](Figura_5.png)

<br>
Exemplo 6<br>
![Texto Alternativo](Figura_6.png)

<br>
Exemplo 7<br>
![Texto Alternativo](Figura_7.png)


